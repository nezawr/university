<h1> Stocastic Gradient Descent on MNIST data </h>
<h2> SGD for Hinge loss</h2>
<p> Optimization for the Hinge loss with L2-regularization </p>

<h4> Accuracy as a function of eta on the validation set</b>:</h4>
<img src="https://github.com/nezawr/university/blob/main/intro_to_ml/Stochastic_Gradient_Descent/charts/1_a.png" alt="alt text" title="Eta" width="500" />

 <h4> Optimized classifier, with 98.9% accuracy: </h4>
 <img src="https://github.com/nezawr/university/blob/main/intro_to_ml/Stochastic_Gradient_Descent/charts/sec1_c_p1.png" alt="alt text" title="Optimizerhinge" width="500" />

<h2> SGD for multi-class cross -entropy</h2>
<p> Optimization for the multi-class entropy loss</p>

<h4> Accuracy as a function of eta on the validation set</b>:</h4>
<img src="https://github.com/nezawr/university/blob/main/intro_to_ml/Stochastic_Gradient_Descent/charts/sec2_optimaleta.png" alt="alt text" title="Eta" width="500" />
 
